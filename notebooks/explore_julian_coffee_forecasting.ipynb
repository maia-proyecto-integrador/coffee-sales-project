{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae9f1c74",
   "metadata": {},
   "source": [
    "# Coffee Demand Forecasting — Notebook End-to-End (H ≤ 7 días)\n",
    "\n",
    "**Objetivo:** Pronosticar **`transactions`** (demanda diaria) por **producto** a **1–7 días** organizado por secciones:\n",
    "\n",
    "1. **Setup & Config**\n",
    "2. **Carga de datos e inspección**\n",
    "3. **Métricas**\n",
    "4. **Splits de backtesting**\n",
    "5. **Baselines (naive1, snaive7, ma7)**\n",
    "6. **LightGBM Direct Multi‑Horizon**\n",
    "7. **Prophet**\n",
    "8. **Ejecución de backtesting y comparación**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888df79",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4958e2f0",
   "metadata": {},
   "source": [
    "## 1) Setup & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd082d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Julian\\\\Estudio\\\\Maestria Inteligencia Artificial\\\\Materias\\\\PROYECTO - DESARROLLO Y DESPLIEGUE DE SOLUCIONES\\\\MICRO - PROYECTOS\\\\REPOSITORIO\\\\coffee-sales-project\\\\data\\\\processed\\\\coffee_ml_features.csv'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paquetes requeridos\n",
    "# !pip install pandas numpy scikit-learn lightgbm prophet --quiet\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuración\n",
    "DATA_PATH_CANDIDATES = [\n",
    "r\"D:\\Julian\\Estudio\\Maestria Inteligencia Artificial\\Materias\\PROYECTO - DESARROLLO Y DESPLIEGUE DE SOLUCIONES\\MICRO - PROYECTOS\\REPOSITORIO\\coffee-sales-project\\data\\processed\\coffee_ml_features.csv\"\n",
    "]\n",
    "TARGET = \"transactions\"\n",
    "HORIZON = 7\n",
    "N_ORIGINS = 4\n",
    "\n",
    "# Resolver ruta de datos\n",
    "for _p in DATA_PATH_CANDIDATES:\n",
    "    if Path(_p).exists():\n",
    "        DATA_PATH = _p\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\"No se encontró coffee_ml_features.csv en rutas conocidas.\")\n",
    "\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44616d2",
   "metadata": {},
   "source": [
    "## 2) Carga de datos e inspección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45bc1825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>transactions</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>first_sale_hour</th>\n",
       "      <th>last_sale_hour</th>\n",
       "      <th>avg_sale_hour</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>total_daily_revenue</th>\n",
       "      <th>market_share_transactions</th>\n",
       "      <th>product_Americano</th>\n",
       "      <th>product_Americano with Milk</th>\n",
       "      <th>product_Cappuccino</th>\n",
       "      <th>product_Cocoa</th>\n",
       "      <th>product_Cortado</th>\n",
       "      <th>product_Espresso</th>\n",
       "      <th>product_Hot Chocolate</th>\n",
       "      <th>product_Latte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>396.3</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-02</td>\n",
       "      <td>86.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>228.1</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-03</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>349.1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>135.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>338.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-03-06</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>170.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>220.1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-03-08</td>\n",
       "      <td>86.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>265.5</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-03-09</td>\n",
       "      <td>86.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>479.4</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-03-10</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>231.6</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  revenue  transactions  avg_price  first_sale_hour  \\\n",
       "0 2024-03-01     28.9           1.0       28.9             15.0   \n",
       "1 2024-03-02     86.7           3.0       28.9             12.0   \n",
       "2 2024-03-03     28.9           1.0       28.9             14.0   \n",
       "3 2024-03-04      0.0           0.0        0.0              0.0   \n",
       "4 2024-03-05      0.0           0.0        0.0              0.0   \n",
       "5 2024-03-06     28.9           1.0       28.9             15.0   \n",
       "6 2024-03-07     28.9           1.0       28.9             17.0   \n",
       "7 2024-03-08     86.7           3.0       28.9             15.0   \n",
       "8 2024-03-09     86.7           3.0       28.9             14.0   \n",
       "9 2024-03-10     30.0           1.0       30.0              9.0   \n",
       "\n",
       "   last_sale_hour  avg_sale_hour  year  month  day  ...  total_daily_revenue  \\\n",
       "0            15.0      15.000000  2024      3    1  ...                396.3   \n",
       "1            19.0      15.666667  2024      3    2  ...                228.1   \n",
       "2            14.0      14.000000  2024      3    3  ...                349.1   \n",
       "3             0.0       0.000000  2024      3    4  ...                135.2   \n",
       "4             0.0       0.000000  2024      3    5  ...                338.5   \n",
       "5            15.0      15.000000  2024      3    6  ...                170.2   \n",
       "6            17.0      17.000000  2024      3    7  ...                220.1   \n",
       "7            16.0      15.666667  2024      3    8  ...                265.5   \n",
       "8            14.0      14.000000  2024      3    9  ...                479.4   \n",
       "9             9.0       9.000000  2024      3   10  ...                231.6   \n",
       "\n",
       "   market_share_transactions  product_Americano  product_Americano with Milk  \\\n",
       "0                   0.090909               True                        False   \n",
       "1                   0.428571               True                        False   \n",
       "2                   0.100000               True                        False   \n",
       "3                   0.000000               True                        False   \n",
       "4                   0.000000               True                        False   \n",
       "5                   0.200000               True                        False   \n",
       "6                   0.166667               True                        False   \n",
       "7                   0.375000               True                        False   \n",
       "8                   0.214286               True                        False   \n",
       "9                   0.142857               True                        False   \n",
       "\n",
       "   product_Cappuccino  product_Cocoa  product_Cortado  product_Espresso  \\\n",
       "0               False          False            False             False   \n",
       "1               False          False            False             False   \n",
       "2               False          False            False             False   \n",
       "3               False          False            False             False   \n",
       "4               False          False            False             False   \n",
       "5               False          False            False             False   \n",
       "6               False          False            False             False   \n",
       "7               False          False            False             False   \n",
       "8               False          False            False             False   \n",
       "9               False          False            False             False   \n",
       "\n",
       "   product_Hot Chocolate  product_Latte  \n",
       "0                  False          False  \n",
       "1                  False          False  \n",
       "2                  False          False  \n",
       "3                  False          False  \n",
       "4                  False          False  \n",
       "5                  False          False  \n",
       "6                  False          False  \n",
       "7                  False          False  \n",
       "8                  False          False  \n",
       "9                  False          False  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff2e94c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "      <th>n_nulls</th>\n",
       "      <th>n_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>revenue</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transactions</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_price</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first_sale_hour</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>last_sale_hour</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>avg_sale_hour</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>year</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>month</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dayofweek</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>quarter</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>week_of_year</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>is_weekend</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is_month_start</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>is_month_end</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>month_sin</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>month_cos</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dayofweek_sin</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dayofweek_cos</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>transactions_lag_1</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>transactions_lag_7</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>transactions_lag_14</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>transactions_roll_3</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>transactions_roll_7</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>transactions_roll_30</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>transactions_vol_7</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>total_daily_transactions</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>total_daily_revenue</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>market_share_transactions</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>product_Americano</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>product_Americano with Milk</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>product_Cappuccino</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>product_Cocoa</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>product_Cortado</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>product_Espresso</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>product_Hot Chocolate</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>product_Latte</td>\n",
       "      <td>bool</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         column           dtype  n_nulls  n_unique\n",
       "0                          date  datetime64[ns]        0       388\n",
       "1                       revenue         float64        0       113\n",
       "2                  transactions         float64        0        14\n",
       "3                     avg_price         float64        0        47\n",
       "4               first_sale_hour         float64        0        18\n",
       "5                last_sale_hour         float64        0        17\n",
       "6                 avg_sale_hour         float64        0       155\n",
       "7                          year           int64        0         2\n",
       "8                         month           int64        0        12\n",
       "9                           day           int64        0        31\n",
       "10                    dayofweek           int64        0         7\n",
       "11                      quarter           int64        0         4\n",
       "12                 week_of_year           int64        0        52\n",
       "13                   is_weekend           int64        0         2\n",
       "14               is_month_start           int64        0         2\n",
       "15                 is_month_end           int64        0         2\n",
       "16                    month_sin         float64        0        11\n",
       "17                    month_cos         float64        0        11\n",
       "18                dayofweek_sin         float64        0         7\n",
       "19                dayofweek_cos         float64        0         7\n",
       "20           transactions_lag_1         float64        0        14\n",
       "21           transactions_lag_7         float64        0        14\n",
       "22          transactions_lag_14         float64        0        14\n",
       "23          transactions_roll_3         float64        0        28\n",
       "24          transactions_roll_7         float64        0        57\n",
       "25         transactions_roll_30         float64        0       250\n",
       "26           transactions_vol_7         float64        0       730\n",
       "27     total_daily_transactions         float64        0        26\n",
       "28          total_daily_revenue         float64        0       296\n",
       "29    market_share_transactions         float64        0       102\n",
       "30            product_Americano            bool        0         2\n",
       "31  product_Americano with Milk            bool        0         2\n",
       "32           product_Cappuccino            bool        0         2\n",
       "33                product_Cocoa            bool        0         2\n",
       "34              product_Cortado            bool        0         2\n",
       "35             product_Espresso            bool        0         2\n",
       "36        product_Hot Chocolate            bool        0         2\n",
       "37                product_Latte            bool        0         2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = pd.DataFrame({\n",
    "    \"column\": df.columns,\n",
    "    \"dtype\": [str(t) for t in df.dtypes],\n",
    "    \"n_nulls\": df.isna().sum().values,\n",
    "    \"n_unique\": df.nunique().values,\n",
    "})\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2ef4059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2024-03-01 00:00:00'),\n",
       " Timestamp('2025-03-23 00:00:00'),\n",
       " (3104, 38))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"date\"].min(), df[\"date\"].max(), df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ca763",
   "metadata": {},
   "source": [
    "## 3) Métricas  — MAE, RMSE, sMAPE y resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40118b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs(y_true[mask] - y_pred[mask]))\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    return float(np.sqrt(np.mean((y_true[mask] - y_pred[mask]) ** 2)))\n",
    "\n",
    "def mape(y_true, y_pred, epsilon: float = 1e-6, ignore_zeros: bool = True):\n",
    "    \"\"\"\n",
    "    MAPE en %.\n",
    "\n",
    "    Por defecto ignoramos los puntos donde |y_true| ~ 0 porque el MAPE clásico explota ahí.\n",
    "    Si no se ignoran, usar ignore_zeros=False y reemplazar denominador por epsilon.\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    if ignore_zeros:\n",
    "        mask = np.abs(y_true) > epsilon\n",
    "        if mask.sum() == 0:\n",
    "            return np.nan\n",
    "        return float(np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0)\n",
    "    else:\n",
    "        denom = np.where(np.abs(y_true) < epsilon, epsilon, np.abs(y_true))\n",
    "        return float(np.mean(np.abs((y_true - y_pred)) / denom) * 100.0)\n",
    "\n",
    "def smape(y_true, y_pred, epsilon: float = 1e-6):\n",
    "    \"\"\"sMAPE en % (estable ante ceros).\"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred)).clip(min=epsilon)\n",
    "    return float(np.mean(2.0 * np.abs(y_pred - y_true) / denom) * 100.0)\n",
    "\n",
    "\n",
    "\n",
    "def summarize_metrics(df, target_col: str = \"y\"):\n",
    "    \"\"\"\n",
    "    Devuelve:\n",
    "      - by_h: DataFrame con métricas por horizonte (h)\n",
    "      - overall: dict con métricas globales\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for h, g in df.groupby(\"h\"):\n",
    "        out[h] = {\n",
    "            \"MAE\": mae(g[target_col], g[\"yhat\"]),\n",
    "            \"RMSE\": rmse(g[target_col], g[\"yhat\"]),\n",
    "            \"MAPE\": mape(g[target_col], g[\"yhat\"], ignore_zeros=True),\n",
    "            \"sMAPE\": smape(g[target_col], g[\"yhat\"]),\n",
    "        }\n",
    "    overall = {\n",
    "        \"MAE\": mae(df[target_col], df[\"yhat\"]),\n",
    "        \"RMSE\": rmse(df[target_col], df[\"yhat\"]),\n",
    "        \"MAPE\": mape(df[target_col], df[\"yhat\"], ignore_zeros=True),\n",
    "        \"sMAPE\": smape(df[target_col], df[\"yhat\"]),\n",
    "    }\n",
    "    return pd.DataFrame(out).T, overall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd45f93c",
   "metadata": {},
   "source": [
    "## 4) Splits de backtesting (rolling-origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "615bd48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Timestamp('2025-02-23 00:00:00'),\n",
       "  Timestamp('2025-02-24 00:00:00'),\n",
       "  Timestamp('2025-03-02 00:00:00')),\n",
       " (Timestamp('2025-03-02 00:00:00'),\n",
       "  Timestamp('2025-03-03 00:00:00'),\n",
       "  Timestamp('2025-03-09 00:00:00')),\n",
       " (Timestamp('2025-03-09 00:00:00'),\n",
       "  Timestamp('2025-03-10 00:00:00'),\n",
       "  Timestamp('2025-03-16 00:00:00')),\n",
       " (Timestamp('2025-03-16 00:00:00'),\n",
       "  Timestamp('2025-03-17 00:00:00'),\n",
       "  Timestamp('2025-03-23 00:00:00'))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "def rolling_origins(date_index: pd.Series, n_origins: int = 4, horizon: int = 7):\n",
    "    unique_dates = pd.Series(pd.to_datetime(pd.unique(date_index))).sort_values()\n",
    "    anchors = [unique_dates.iloc[-(i+1)*horizon] for i in range(n_origins)][::-1]\n",
    "    splits: List[Tuple[pd.Timestamp, pd.Timestamp, pd.Timestamp]] = []\n",
    "    for anchor in anchors:\n",
    "        train_end = anchor - pd.Timedelta(days=1)\n",
    "        test_start = anchor\n",
    "        test_end = anchor + pd.Timedelta(days=horizon - 1)\n",
    "        splits.append((train_end, test_start, test_end))\n",
    "    return splits\n",
    "\n",
    "splits_demo = rolling_origins(df[\"date\"], n_origins=4, horizon=7)\n",
    "splits_demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed17bd0",
   "metadata": {},
   "source": [
    "## 5) Baselines — naive1, seasonal-naive(7), moving-average(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f558711",
   "metadata": {},
   "source": [
    "_baseline_predict(train, test_dates, horizon, target, kind):\n",
    "\n",
    "naive1: repite el último valor observado.\n",
    "\n",
    "snaive7: repite el patrón de los últimos 7 días.\n",
    "\n",
    "ma7: usa la media de los últimos 7 días.\n",
    "\n",
    "Define baselines por  producto.\n",
    "\n",
    "Hace un smoke test en el primer split: entrena con el bloque de train y genera predicciones para el rango de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd0798b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>product</th>\n",
       "      <th>h</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>Americano</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-25</td>\n",
       "      <td>Americano</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-26</td>\n",
       "      <td>Americano</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>Americano</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>Americano</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    product  h  yhat\n",
       "0 2025-02-24  Americano  1   7.0\n",
       "1 2025-02-25  Americano  2   5.0\n",
       "2 2025-02-26  Americano  3   6.0\n",
       "3 2025-02-27  Americano  4   8.0\n",
       "4 2025-02-28  Americano  5  11.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASELINE_NAMES = [\"naive1\", \"snaive7\", \"ma7\"]\n",
    "\n",
    "def _by_product(df: pd.DataFrame):\n",
    "    prod_cols = [c for c in df.columns if c.startswith(\"product_\")]\n",
    "    dfx = df.copy()\n",
    "    if len(prod_cols) == 0:\n",
    "        raise ValueError(\"No se encontraron columnas product_* (one-hot).\")\n",
    "    dfx[\"product\"] = dfx[prod_cols].idxmax(axis=1).str.replace(\"product_\", \"\", regex=False)\n",
    "    return dfx\n",
    "\n",
    "def _baseline_predict(train: pd.DataFrame, test_dates: pd.DatetimeIndex, horizon: int, target: str, kind: str):\n",
    "    pieces = []\n",
    "    for prod, g in train.groupby(\"product\"):\n",
    "        g = g.sort_values(\"date\")\n",
    "        if kind == \"naive1\":\n",
    "            last = g[target].iloc[-1]\n",
    "            preds = [last] * horizon\n",
    "        elif kind == \"snaive7\":\n",
    "            hist = g[target].iloc[-7:].tolist()\n",
    "            if len(hist) < 7:\n",
    "                hist = [g[target].iloc[-1]] * 7\n",
    "            preds = hist\n",
    "        elif kind == \"ma7\":\n",
    "            window = g[target].iloc[-7:]\n",
    "            meanv = float(window.mean()) if len(window) > 0 else float(g[target].iloc[-1])\n",
    "            preds = [meanv] * horizon\n",
    "        else:\n",
    "            raise ValueError(kind)\n",
    "        dfp = pd.DataFrame({\n",
    "            \"date\": test_dates,\n",
    "            \"product\": prod,\n",
    "            \"h\": list(range(1, horizon + 1)),\n",
    "            \"yhat\": preds[:horizon],\n",
    "        })\n",
    "        pieces.append(dfp)\n",
    "    return pd.concat(pieces, ignore_index=True)\n",
    "\n",
    "df_prod = _by_product(df)\n",
    "(train_end, test_start, test_end) = splits_demo[0]\n",
    "train = df_prod[df_prod[\"date\"] <= train_end]\n",
    "test = df_prod[(df_prod[\"date\"] >= test_start) & (df_prod[\"date\"] <= test_end)].copy()\n",
    "preds = _baseline_predict(train, pd.date_range(test_start, test_end, freq=\"D\"), 7, \"transactions\", \"snaive7\")\n",
    "preds.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071fbb9b",
   "metadata": {},
   "source": [
    "## 6) LightGBM — Direct Multi‑Horizon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00129263",
   "metadata": {},
   "source": [
    "Se quiere predecir 7 días de demanda por producto\n",
    "\n",
    "Directa por horizonte: 7 modelos distintos, uno por cada día futuro\n",
    "\n",
    "No hay propagación de errores recursivamente; cada modelo aprende directamente su horizonte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62141b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm prophet --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70350fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def _build_direct_labels(df: pd.DataFrame, target: str, H: int = 7):\n",
    "    dfx = df.sort_values([\"product\", \"date\"]).copy()\n",
    "    for h in range(1, H + 1):\n",
    "        dfx[f\"y_{h}\"] = dfx.groupby(\"product\")[target].shift(-h)\n",
    "    return dfx\n",
    "\n",
    "def _feature_columns(df: pd.DataFrame, target: str):\n",
    "    drop_like = {target, \"date\", \"product\"}\n",
    "    cols = [c for c in df.columns if c not in drop_like and not c.startswith(\"y_\")]\n",
    "    return [c for c in cols if pd.api.types.is_numeric_dtype(df[c])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd16e81",
   "metadata": {},
   "source": [
    "## 7) Prophet — estacionalidad semanal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f8777",
   "metadata": {},
   "source": [
    "Modela cada producto por separado con Prophet activando estacionalidad semanal (weekly_seasonality=True).\n",
    "\n",
    "Entrena con histórico hasta train_end y hace horizon días a futuro.\n",
    "\n",
    "Consolidación: une las predicciones por producto y por fecha del bloque de test, calcula h y luego evalúa con summarize_metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13aa8146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f4a9ac",
   "metadata": {},
   "source": [
    "## 8) Backtesting end‑to‑end y comparación de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b35da968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        MAE      RMSE       MAPE      sMAPE\n",
       " 1  1.507440  2.175300  65.109435  74.592093\n",
       " 2  1.138393  1.729410  61.355219  76.410945\n",
       " 3  1.209821  1.719919  60.912698  82.363135\n",
       " 4  1.209821  1.747386  62.577839  80.546706\n",
       " 5  1.534226  2.322207  61.316672  77.595400\n",
       " 6  0.944940  1.385435  74.751984  91.046764\n",
       " 7  0.800595  1.127878  74.603175  92.678669,\n",
       " {'MAE': 1.1921768707482994,\n",
       "  'RMSE': 1.7855952341267196,\n",
       "  'MAPE': 64.93002257883211,\n",
       "  'sMAPE': 82.17624474604864})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "df_prod = _by_product(df)\n",
    "splits = rolling_origins(df_prod[\"date\"], n_origins=4, horizon=7)\n",
    "\n",
    "all_results = []\n",
    "for (train_end, test_start, test_end) in splits:\n",
    "    train = df_prod[df_prod[\"date\"] <= train_end]\n",
    "    test = df_prod[(df_prod[\"date\"] >= test_start) & (df_prod[\"date\"] <= test_end)].copy()\n",
    "    for name in [\"naive1\", \"snaive7\", \"ma7\"]:\n",
    "        preds = _baseline_predict(train, pd.date_range(test_start, test_end, freq=\"D\"), 7, \"transactions\", name)\n",
    "        merged = test.merge(preds, on=[\"date\", \"product\"], how=\"left\")\n",
    "        merged[\"model\"] = name\n",
    "        all_results.append(merged[[\"date\", \"product\", \"transactions\", \"h\", \"yhat\", \"model\"]])\n",
    "baseline_results = pd.concat(all_results, ignore_index=True)\n",
    "by_h_baseline, overall_baseline = summarize_metrics(baseline_results.rename(columns={\"transactions\": \"y\"}))\n",
    "by_h_baseline, overall_baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e59ee5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Baselines guardados'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results.to_csv(r\"D:\\Julian\\Estudio\\Maestria Inteligencia Artificial\\Materias\\PROYECTO - DESARROLLO Y DESPLIEGUE DE SOLUCIONES\\MICRO - PROYECTOS\\results\\baselines_forecasts.csv\", index=False)\n",
    "by_h_baseline.to_csv(r\"D:\\Julian\\Estudio\\Maestria Inteligencia Artificial\\Materias\\PROYECTO - DESARROLLO Y DESPLIEGUE DE SOLUCIONES\\MICRO - PROYECTOS\\results\\baselines_metrics_by_h.csv\")\n",
    "pd.DataFrame([overall_baseline]).to_csv(r\"D:\\Julian\\Estudio\\Maestria Inteligencia Artificial\\Materias\\PROYECTO - DESARROLLO Y DESPLIEGUE DE SOLUCIONES\\MICRO - PROYECTOS\\results\\baselines_metrics_overall.csv\", index=False)\n",
    "\"Baselines guardados\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abeb7859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2880, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.125000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2880, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.126736\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2880, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.129514\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2880, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.134722\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2880, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.137500\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2880, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.138542\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2880, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.138542\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1237\n",
      "[LightGBM] [Info] Number of data points in the train set: 2936, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.138283\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1237\n",
      "[LightGBM] [Info] Number of data points in the train set: 2936, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.141349\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1237\n",
      "[LightGBM] [Info] Number of data points in the train set: 2936, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.144414\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1237\n",
      "[LightGBM] [Info] Number of data points in the train set: 2936, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.147139\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1237\n",
      "[LightGBM] [Info] Number of data points in the train set: 2936, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.149864\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1237\n",
      "[LightGBM] [Info] Number of data points in the train set: 2936, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.150886\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1237\n",
      "[LightGBM] [Info] Number of data points in the train set: 2936, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.151567\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1240\n",
      "[LightGBM] [Info] Number of data points in the train set: 2992, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.149398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1240\n",
      "[LightGBM] [Info] Number of data points in the train set: 2992, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.151404\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1240\n",
      "[LightGBM] [Info] Number of data points in the train set: 2992, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.153743\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1240\n",
      "[LightGBM] [Info] Number of data points in the train set: 2992, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.156417\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1240\n",
      "[LightGBM] [Info] Number of data points in the train set: 2992, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.161096\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1240\n",
      "[LightGBM] [Info] Number of data points in the train set: 2992, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.161765\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1240\n",
      "[LightGBM] [Info] Number of data points in the train set: 2992, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.161430\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1245\n",
      "[LightGBM] [Info] Number of data points in the train set: 3048, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.157808\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1245\n",
      "[LightGBM] [Info] Number of data points in the train set: 3048, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.161089\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1245\n",
      "[LightGBM] [Info] Number of data points in the train set: 3048, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.164698\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1245\n",
      "[LightGBM] [Info] Number of data points in the train set: 3048, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.169948\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1245\n",
      "[LightGBM] [Info] Number of data points in the train set: 3048, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.173556\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1245\n",
      "[LightGBM] [Info] Number of data points in the train set: 3048, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.175853\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1245\n",
      "[LightGBM] [Info] Number of data points in the train set: 3048, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 1.175853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        MAE      RMSE       MAPE       sMAPE\n",
       " 1  1.253773  1.700311  51.950336   96.822273\n",
       " 2  1.057390  1.446797  46.922641   98.192148\n",
       " 3  1.282123  1.631269  59.468925   95.938441\n",
       " 4  0.983264  1.282467  60.354614   79.863056\n",
       " 5  1.424265  1.844967  63.476480  100.245654\n",
       " 6  1.105676  1.542267  80.302016  125.367974\n",
       " 7  0.645787  0.755241  44.571646  112.276185,\n",
       " {'MAE': 1.1074682552468154,\n",
       "  'RMSE': 1.494892455218169,\n",
       "  'MAPE': 57.7473501659663,\n",
       "  'sMAPE': 101.24367578327728})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lgbm = _build_direct_labels(df_prod, \"transactions\", H=7)\n",
    "feats = _feature_columns(df_lgbm, \"transactions\")\n",
    "\n",
    "lgbm_all = []\n",
    "for (train_end, test_start, test_end) in splits:\n",
    "    train = df_lgbm[df_lgbm[\"date\"] <= train_end].copy()\n",
    "    test = df_lgbm[(df_lgbm[\"date\"] >= test_start) & (df_lgbm[\"date\"] <= test_end)].copy()\n",
    "    preds_blocks = []\n",
    "    for h in range(1, 8):\n",
    "        y_col = f\"y_{h}\"\n",
    "        tr = train.dropna(subset=[y_col])\n",
    "        if tr.empty:\n",
    "            continue\n",
    "        X_tr = tr[feats]\n",
    "        y_tr = tr[y_col]\n",
    "        model = LGBMRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=31,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            random_state=42,\n",
    "        )\n",
    "        model.fit(X_tr, y_tr)\n",
    "        test_block = test.copy()\n",
    "        test_block[\"h\"] = (test_block[\"date\"] - test_start).dt.days + 1\n",
    "        mask_h = test_block[\"h\"] == h\n",
    "        X_te = test_block.loc[mask_h, feats]\n",
    "        yhat = model.predict(X_te)\n",
    "        out = test_block.loc[mask_h, [\"date\", \"product\"]].copy()\n",
    "        out[\"h\"] = h\n",
    "        out[\"yhat\"] = yhat\n",
    "        preds_blocks.append(out)\n",
    "    if preds_blocks:\n",
    "        fold_preds = pd.concat(preds_blocks, ignore_index=True)\n",
    "        y_true = test[[\"date\", \"product\", \"transactions\"]].copy()\n",
    "        merged = y_true.merge(fold_preds, on=[\"date\", \"product\"], how=\"left\")\n",
    "        merged[\"model\"] = \"lgbm_direct\"\n",
    "        lgbm_all.append(merged)\n",
    "lgbm_results = pd.concat(lgbm_all, ignore_index=True)\n",
    "by_h_lgbm, overall_lgbm = summarize_metrics(lgbm_results.rename(columns={\"transactions\": \"y\"}))\n",
    "by_h_lgbm, overall_lgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30b566c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBM direct guardado'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_results.to_csv(r\"D:\\Julian\\Estudio\\Maestria Inteligencia Artificial\\Materias\\PROYECTO - DESARROLLO Y DESPLIEGUE DE SOLUCIONES\\MICRO - PROYECTOS\\results\\lgbm_direct_forecasts.csv\", index=False)\n",
    "by_h_lgbm.to_csv(r\"D:\\Julian\\Estudio\\Maestria Inteligencia Artificial\\Materias\\PROYECTO - DESARROLLO Y DESPLIEGUE DE SOLUCIONES\\MICRO - PROYECTOS\\results\\lgbm_direct_metrics_by_h.csv\")\n",
    "pd.DataFrame([overall_lgbm]).to_csv(r\"D:\\Julian\\Estudio\\Maestria Inteligencia Artificial\\Materias\\PROYECTO - DESARROLLO Y DESPLIEGUE DE SOLUCIONES\\MICRO - PROYECTOS\\results\\lgbm_direct_metrics_overall.csv\", index=False)\n",
    "\"LGBM direct guardado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f4ade78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:31:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:31:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        MAE      RMSE       MAPE       sMAPE\n",
       " 1  1.273708  1.806059  47.686456   96.989572\n",
       " 2  1.084673  1.558801  46.251176   97.188347\n",
       " 3  1.182781  1.568151  44.258456   73.543084\n",
       " 4  1.071159  1.472168  43.029766   79.961065\n",
       " 5  1.514759  2.166736  48.447347  100.575392\n",
       " 6  1.013972  1.233269  58.726216  125.185653\n",
       " 7  0.713720  0.936127  49.469876  107.978054,\n",
       " {'MAE': 1.1221101513777312,\n",
       "  'RMSE': 1.577073322666212,\n",
       "  'MAPE': 47.542892597250344,\n",
       "  'sMAPE': 97.34588098262145})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_all = []\n",
    "for (train_end, test_start, test_end) in splits:\n",
    "    fold = []\n",
    "    for prod, g in df_prod[df_prod[\"date\"] <= train_end].groupby(\"product\"):\n",
    "        g = g.sort_values(\"date\")\n",
    "        m = Prophet(weekly_seasonality=True, daily_seasonality=False, yearly_seasonality=False)\n",
    "        aux = g.rename(columns={\"date\": \"ds\", \"transactions\": \"y\"})[[\"ds\", \"y\"]]\n",
    "        m.fit(aux)\n",
    "        future = m.make_future_dataframe(periods=7, freq=\"D\", include_history=False)\n",
    "        fcst = m.predict(future)[[\"ds\", \"yhat\"]]\n",
    "        fcst[\"product\"] = prod\n",
    "        fold.append(fcst.rename(columns={\"ds\": \"date\"}))\n",
    "    fold = pd.concat(fold, ignore_index=True)\n",
    "    mask = (fold[\"date\"] >= test_start) & (fold[\"date\"] <= test_end)\n",
    "    fold = fold.loc[mask].copy()\n",
    "    fold[\"h\"] = (fold[\"date\"] - test_start).dt.days + 1\n",
    "    y_true = df_prod[(df_prod[\"date\"] >= test_start) & (df_prod[\"date\"] <= test_end)][[\"date\", \"product\", \"transactions\"]].copy()\n",
    "    merged = y_true.merge(fold, on=[\"date\", \"product\"], how=\"left\")\n",
    "    merged[\"model\"] = \"prophet\"\n",
    "    prophet_all.append(merged)\n",
    "prophet_results = pd.concat(prophet_all, ignore_index=True)\n",
    "by_h_prophet, overall_prophet = summarize_metrics(prophet_results.rename(columns={\"transactions\": \"y\"}))\n",
    "by_h_prophet, overall_prophet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8dc2be63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prophet guardado'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_results.to_csv(r\"D:\\Julian\\Estudio\\Maestria Inteligencia Artificial\\Materias\\PROYECTO - DESARROLLO Y DESPLIEGUE DE SOLUCIONES\\MICRO - PROYECTOS\\results\\prophet_forecasts.csv\", index=False)\n",
    "by_h_prophet.to_csv(r\"D:\\Julian\\Estudio\\Maestria Inteligencia Artificial\\Materias\\PROYECTO - DESARROLLO Y DESPLIEGUE DE SOLUCIONES\\MICRO - PROYECTOS\\results\\prophet_metrics_by_h.csv\")\n",
    "pd.DataFrame([overall_prophet]).to_csv(r\"D:\\Julian\\Estudio\\Maestria Inteligencia Artificial\\Materias\\PROYECTO - DESARROLLO Y DESPLIEGUE DE SOLUCIONES\\MICRO - PROYECTOS\\results\\prophet_metrics_overall.csv\", index=False)\n",
    "\"Prophet guardado\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e09da",
   "metadata": {},
   "source": [
    "### Comparación modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "411a9dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.192177</td>\n",
       "      <td>1.785595</td>\n",
       "      <td>64.930023</td>\n",
       "      <td>82.176245</td>\n",
       "      <td>baselines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.122110</td>\n",
       "      <td>1.577073</td>\n",
       "      <td>47.542893</td>\n",
       "      <td>97.345881</td>\n",
       "      <td>prophet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.107468</td>\n",
       "      <td>1.494892</td>\n",
       "      <td>57.747350</td>\n",
       "      <td>101.243676</td>\n",
       "      <td>lgbm_direct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE      RMSE       MAPE       sMAPE        model\n",
       "0  1.192177  1.785595  64.930023   82.176245    baselines\n",
       "2  1.122110  1.577073  47.542893   97.345881      prophet\n",
       "1  1.107468  1.494892  57.747350  101.243676  lgbm_direct"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "RESULTS_PATH = Path(r\"D:\\Julian\\Estudio\\Maestria Inteligencia Artificial\\Materias\\PROYECTO - DESARROLLO Y DESPLIEGUE DE SOLUCIONES\\MICRO - PROYECTOS\\results\")  # <-- ajusta a tu ruta real\n",
    "paths = list(RESULTS_PATH.glob(\"*_metrics_overall.csv\"))\n",
    "rows = []\n",
    "for p in paths:\n",
    "    dfm = pd.read_csv(p)\n",
    "    model = p.name.replace(\"_metrics_overall.csv\", \"\")\n",
    "    row = dfm.iloc[0].to_dict()\n",
    "    row[\"model\"] = model\n",
    "    rows.append(row)\n",
    "rank = pd.DataFrame(rows).sort_values(\"sMAPE\")\n",
    "rank\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
